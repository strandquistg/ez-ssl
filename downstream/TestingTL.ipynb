{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os, math, pdb, glob, os, sys, natsort, h5py, mne\n",
    "#Choose GPU 0 as a default\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Flatten, Dense, Activation\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/zsteineh/cnn_hilbert/cnn_hilbert_workspace')\n",
    "import hilbert_DL_utils\n",
    "from hilbert_DL_utils import load_data\n",
    "sys.path.append('/home/zsteineh/ez-ssl/pretasks')\n",
    "from make_ecog_data import get_speech_epochs \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 2\n",
    "datatype = \"speech\" #model\n",
    "pretask_type = 'sig_tran' #sig_tran\n",
    "model_dir = '/data1/users/gsquist/state_decoder/accuracy_outputs/a0f66459/class_ssl/'\n",
    "model_name = pretask_type+'_'+datatype+'_htnet_fold_'+str(fold)+'.h5'\n",
    "\n",
    "model_fname = model_dir + model_name\n",
    "\n",
    "norm_rate = 0.25\n",
    "wrist_lp = '/data1/users/stepeter/cnn_hilbert/ecog_data/xarray/'\n",
    "speech_lp = '/data2/users/gsquist/speech_project/epochd_ecog_data/'\n",
    "pats_ids_in = ['a0f66459']\n",
    "test_day = 'last'\n",
    "n_chans_all=64\n",
    "tlim=[-1,1]\n",
    "n_folds = 1\n",
    "\n",
    "optimizer='adam'\n",
    "loss='binary_crossentropy'\n",
    "patience = 15\n",
    "early_stop_monitor='val_loss'\n",
    "epochs=64\n",
    "sp = '/home/zsteineh/ez_ssl_results/'\n",
    "chckpt_path = sp+'checkpoint_gen_tl_'+datatype+'_'+pats_ids_in[0]+'_fold'+str(fold)+'.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for sjb a0f66459 f_load is ['/data2/users/gsquist/speech_project/epochd_ecog_data/a0f66459/speak_silent/a0f66459_speak_silent_163events_5_epo.fif', '/data2/users/gsquist/speech_project/epochd_ecog_data/a0f66459/speak_silent/a0f66459_speak_silent_243events_4_epo.fif']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-e396d24e6fc7>:15: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs_train = mne.read_epochs(eps_to_file[max_eps])\n",
      "<ipython-input-11-e396d24e6fc7>:16: RuntimeWarning: The events passed to the Epochs constructor are not chronologically ordered.\n",
      "  epochs_test = mne.read_epochs(eps_to_file[min_eps])\n"
     ]
    }
   ],
   "source": [
    "if datatype == \"wrist\":\n",
    "        X,y,x_test,y_test,sbj_order_all,sbj_order_test_last = load_data(pats_ids_in, wrist_lp,\n",
    "                                                              n_chans_all=n_chans_all,\n",
    "                                                              test_day=test_day, tlim=tlim)\n",
    "elif datatype == \"speech\":\n",
    "    sbj = pats_ids_in[0]\n",
    "    sigs, labs = [], []\n",
    "    f_load = natsort.natsorted(glob.glob(speech_lp+sbj+'/speak_silent/'+'*_epo.fif'))\n",
    "    print(\"for sjb\",sbj, \"f_load is\",f_load)\n",
    "    eps_to_file = {}\n",
    "    for i, f in enumerate(f_load):\n",
    "        eps = f_load[i].split('/')[-1].split('_')[3][:3]\n",
    "        eps_to_file[eps] = f_load[i]\n",
    "    max_eps, min_eps = max(eps_to_file, key=eps_to_file.get), min(eps_to_file, key=eps_to_file.get)\n",
    "    epochs_train = mne.read_epochs(eps_to_file[max_eps])\n",
    "    epochs_test = mne.read_epochs(eps_to_file[min_eps])\n",
    "    X = epochs_train.get_data()\n",
    "    x_test = epochs_test.get_data()\n",
    "\n",
    "    y = epochs_train.events[:,-1]\n",
    "    y_test = epochs_test.events[:,-1]\n",
    "\n",
    "#     Y_trainval_cat = np_utils.to_categorical(labels_train)\n",
    "#     Y_test = np_utils.to_categorical(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = len(np.unique(y))\n",
    "order_inds = np.arange(len(y))\n",
    "np.random.shuffle(order_inds)\n",
    "X = X[order_inds,...]\n",
    "y = y[order_inds]\n",
    "order_inds_test = np.arange(len(y_test))\n",
    "np.random.shuffle(order_inds_test)\n",
    "x_test = x_test[order_inds_test,...]\n",
    "y_test = y_test[order_inds_test]\n",
    "y2 = np_utils.to_categorical(y-1)\n",
    "y_test2 = np_utils.to_categorical(y_test-1)\n",
    "X2 = np.expand_dims(X,1)\n",
    "X_test2 = np.expand_dims(x_test,1)\n",
    "\n",
    "split_len = int(X2.shape[0]*0.2)\n",
    "last_epochs = np.zeros([n_folds,2])\n",
    "\n",
    "val_inds = np.arange(0,split_len)+(0*split_len)\n",
    "train_inds = np.setdiff1d(np.arange(X2.shape[0]),val_inds) #take all events not in val set\n",
    "\n",
    "x_train = X2[train_inds,...]\n",
    "y_train = y2[train_inds]\n",
    "x_val = X2[val_inds,...]\n",
    "y_val = y2[val_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1, 64, 3001)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 8, 64, 3001)       512       \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 8, 64, 3001)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 8, 64, 3001)       32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d (DepthwiseC (None, 16, 1, 3001)       1024      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 1, 3001)       64        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16, 1, 3001)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 16, 1, 750)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 1, 750)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d (SeparableC (None, 16, 1, 750)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 1, 750)        64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16, 1, 750)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 16, 1, 93)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 1, 93)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1488)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 7445      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 9,653\n",
      "Trainable params: 9,573\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretask_model = tf.keras.models.load_model(model_fname)\n",
    "pretask_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if pretask_type == 'rel_pos':\n",
    "    sig_tran_model_fname = model_dir + 'sig_tran_' + datatype + '_htnet_fold_'+str(fold)+'.h5'\n",
    "    sig_tran_pretask_model = tf.keras.models.load_model(sig_tran_model_fname)\n",
    "    x = sig_tran_pretask_model.layers[-4].output\n",
    "    x = Flatten(name = 'flatten2')(x)\n",
    "    x = Dense(nb_classes, name = 'dense2', kernel_constraint = max_norm(norm_rate))(x)\n",
    "    softmax = Activation('softmax', name = 'softmax2')(x)\n",
    "\n",
    "    transfer_model = Model(inputs=sig_tran_pretask_model.input, outputs=softmax)\n",
    "    transfer_model.load_weights(model_fname, by_name=True)\n",
    "\n",
    "else:\n",
    "    x = pretask_model.layers[-3].output\n",
    "    # x = Flatten(name = 'flatten2')(x)\n",
    "    x = Dense(nb_classes, name = 'dense', kernel_constraint = max_norm(norm_rate))(x)\n",
    "    softmax = Activation('softmax', name = 'softmax')(x)\n",
    "\n",
    "    transfer_model = Model(inputs=pretask_model.input, outputs=softmax)\n",
    "\n",
    "# Set only last 3 layers to be trainable\n",
    "for l in transfer_model.layers:\n",
    "    l.trainable = False\n",
    "for l in transfer_model.layers[-3:]:\n",
    "    l.trainable = True #train last 3 layers\n",
    "    \n",
    "\n",
    "transfer_model.get_layer('depthwise_conv2d').trainable = True\n",
    "\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model.compile(loss=loss, optimizer=optimizer, metrics = ['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath=chckpt_path,verbose=1,save_best_only=True)\n",
    "early_stop = EarlyStopping(monitor=early_stop_monitor, mode='min',\n",
    "                               patience=patience, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run tests before finetuning model\n",
    "acc_lst = []\n",
    "preds = transfer_model.predict(x_train).argmax(axis = -1) \n",
    "acc_lst.append(np.mean(preds == y_train.argmax(axis=-1)))\n",
    "preds = transfer_model.predict(x_val).argmax(axis=-1)\n",
    "acc_lst.append(np.mean(preds == y_val.argmax(axis=-1)))\n",
    "preds = transfer_model.predict(X_test2).argmax(axis = -1)\n",
    "acc_lst.append(np.mean(preds == y_test2.argmax(axis=-1)))\n",
    "\n",
    "print(np.asarray(acc_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = transfer_model.fit(x_train, y_train, batch_size = 16, epochs = epochs, \n",
    "                        verbose = 2, validation_data=(x_val, y_val),\n",
    "                        callbacks=[checkpointer,early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model.load_weights(chckpt_path)\n",
    "acc_lst = []\n",
    "preds = transfer_model.predict(x_train).argmax(axis = -1) \n",
    "acc_lst.append(np.mean(preds == y_train.argmax(axis=-1)))\n",
    "preds = transfer_model.predict(x_val).argmax(axis=-1)\n",
    "acc_lst.append(np.mean(preds == y_val.argmax(axis=-1)))\n",
    "preds = transfer_model.predict(X_test2).argmax(axis = -1)\n",
    "acc_lst.append(np.mean(preds == y_test2.argmax(axis=-1)))\n",
    "\n",
    "print(np.asarray(acc_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cloned = tf.keras.models.clone_model(transfer_model)\n",
    "acc_lst = []\n",
    "preds = model_cloned.predict(x_train).argmax(axis = -1) \n",
    "acc_lst.append(np.mean(preds == y_train.argmax(axis=-1)))\n",
    "preds = model_cloned.predict(x_val).argmax(axis=-1)\n",
    "acc_lst.append(np.mean(preds == y_val.argmax(axis=-1)))\n",
    "preds = model_cloned.predict(X_test2).argmax(axis = -1)\n",
    "acc_lst.append(np.mean(preds == y_test2.argmax(axis=-1)))\n",
    "print(acc_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chckpt_path = sp+'checkpoint_gen_tsupervised_'+pats_ids_in[0]+'_fold'+str(fold)+'.h5'\n",
    "model_cloned.compile(loss=loss, optimizer=optimizer, metrics = ['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath=chckpt_path,verbose=1,save_best_only=True)\n",
    "early_stop = EarlyStopping(monitor=early_stop_monitor, mode='min',\n",
    "                               patience=patience, verbose=0)\n",
    "h = model_cloned.fit(x_train, y_train, batch_size = 16, epochs = epochs, \n",
    "                        verbose = 2, validation_data=(x_val, y_val),\n",
    "                        callbacks=[checkpointer,early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cloned.load_weights(chckpt_path)\n",
    "acc_lst = []\n",
    "preds = model_cloned.predict(x_train).argmax(axis = -1) \n",
    "acc_lst.append(np.mean(preds == y_train.argmax(axis=-1)))\n",
    "preds = model_cloned.predict(x_val).argmax(axis=-1)\n",
    "acc_lst.append(np.mean(preds == y_val.argmax(axis=-1)))\n",
    "preds = model_cloned.predict(X_test2).argmax(axis = -1)\n",
    "acc_lst.append(np.mean(preds == y_test2.argmax(axis=-1)))\n",
    "print(acc_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ez_ss_dl_venv",
   "language": "python",
   "name": "ez_ss_dl_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
