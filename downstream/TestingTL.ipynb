{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "#Choose GPU 0 as a default\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Flatten, Dense, Activation\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/zsteineh/cnn_hilbert/cnn_hilbert_workspace')\n",
    "import hilbert_DL_utils\n",
    "from hilbert_DL_utils import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 2\n",
    "pretask_type = 'rel_pos'\n",
    "model_dir = '/data1/users/gsquist/state_decoder/accuracy_outputs/a0f66459/class_ssl/'\n",
    "model_name = pretask_type+'_model_htnet_fold_'+str(fold)+'.h5'\n",
    "\n",
    "model_fname = model_dir + model_name\n",
    "\n",
    "norm_rate = 0.25\n",
    "wrist_lp = '/data1/users/stepeter/cnn_hilbert/ecog_data/xarray/'\n",
    "pats_ids_in = ['a0f66459']\n",
    "test_day = 'last'\n",
    "n_chans_all=64\n",
    "tlim=[-1,1]\n",
    "n_folds = 1\n",
    "\n",
    "optimizer='adam'\n",
    "loss='binary_crossentropy'\n",
    "patience = 15\n",
    "early_stop_monitor='val_loss'\n",
    "epochs=64\n",
    "sp = '/home/zsteineh/ez_ssl_results/'\n",
    "chckpt_path = sp+'checkpoint_gen_tl_'+pats_ids_in[0]+'_fold'+str(fold)+'.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X,y,x_test,y_test,sbj_order_all,sbj_order_test_last = load_data(pats_ids_in, wrist_lp,\n",
    "                                                              n_chans_all=n_chans_all,\n",
    "                                                              test_day=test_day, tlim=tlim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = len(np.unique(y))\n",
    "order_inds = np.arange(len(y))\n",
    "np.random.shuffle(order_inds)\n",
    "X = X[order_inds,...]\n",
    "y = y[order_inds]\n",
    "order_inds_test = np.arange(len(y_test))\n",
    "np.random.shuffle(order_inds_test)\n",
    "# X_test = X_test[order_inds_test,...]\n",
    "# y_test = y_test[order_inds_test]\n",
    "y2 = np_utils.to_categorical(y-1)\n",
    "y_test2 = np_utils.to_categorical(y_test-1)\n",
    "X2 = np.expand_dims(X,1)\n",
    "X_test2 = np.expand_dims(x_test,1)\n",
    "\n",
    "split_len = int(X2.shape[0]*0.2)\n",
    "last_epochs = np.zeros([n_folds,2])\n",
    "\n",
    "val_inds = np.arange(0,split_len)+(0*split_len)\n",
    "train_inds = np.setdiff1d(np.arange(X2.shape[0]),val_inds) #take all events not in val set\n",
    "\n",
    "x_train = X2[train_inds,...]\n",
    "y_train = y2[train_inds]\n",
    "x_val = X2[val_inds,...]\n",
    "y_val = y2[val_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1, 64, 2002)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 8, 64, 2002)       512       \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 8, 64, 2002)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 8, 64, 2002)       32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d (DepthwiseC (None, 16, 1, 2002)       1024      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 1, 2002)       64        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16, 1, 2002)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 16, 1, 500)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 1, 500)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d (SeparableC (None, 16, 1, 500)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 1, 500)        64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16, 1, 500)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 16, 1, 62)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 1, 62)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 992)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 1986      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 4,194\n",
      "Trainable params: 4,114\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretask_model = tf.keras.models.load_model(model_fname)\n",
    "pretask_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1, 64, 501)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 8, 64, 501)        512       \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 8, 64, 501)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 8, 64, 501)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d (DepthwiseC (None, 16, 1, 501)        1024      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 1, 501)        64        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16, 1, 501)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 16, 1, 125)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 1, 125)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d (SeparableC (None, 16, 1, 125)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 1, 125)        64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16, 1, 125)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 16, 1, 15)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 1, 15)         0         \n",
      "_________________________________________________________________\n",
      "flatten2 (Flatten)           (None, 240)               0         \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 2)                 482       \n",
      "_________________________________________________________________\n",
      "softmax2 (Activation)        (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 2,690\n",
      "Trainable params: 1,506\n",
      "Non-trainable params: 1,184\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if pretask_type == 'rel_pos':\n",
    "    sig_tran_model_fname = model_dir + 'sig_tran_model_htnet_fold_'+str(fold)+'.h5'\n",
    "    sig_tran_pretask_model = tf.keras.models.load_model(sig_tran_model_fname)\n",
    "    x = sig_tran_pretask_model.layers[-4].output\n",
    "    x = Flatten(name = 'flatten2')(x)\n",
    "    x = Dense(nb_classes, name = 'dense2', kernel_constraint = max_norm(norm_rate))(x)\n",
    "    softmax = Activation('softmax', name = 'softmax2')(x)\n",
    "\n",
    "    transfer_model = Model(inputs=sig_tran_pretask_model.input, outputs=softmax)\n",
    "    transfer_model.load_weights(model_fname, by_name=True)\n",
    "\n",
    "else:\n",
    "    x = pretask_model.layers[-3].output\n",
    "    # x = Flatten(name = 'flatten2')(x)\n",
    "    x = Dense(nb_classes, name = 'dense', kernel_constraint = max_norm(norm_rate))(x)\n",
    "    softmax = Activation('softmax', name = 'softmax')(x)\n",
    "\n",
    "    transfer_model = Model(inputs=pretask_model.input, outputs=softmax)\n",
    "\n",
    "# Set only last 3 layers to be trainable\n",
    "for l in transfer_model.layers:\n",
    "    l.trainable = False\n",
    "for l in transfer_model.layers[-3:]:\n",
    "    l.trainable = True #train last 3 layers\n",
    "    \n",
    "\n",
    "transfer_model.get_layer('depthwise_conv2d').trainable = True\n",
    "\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model.compile(loss=loss, optimizer=optimizer, metrics = ['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath=chckpt_path,verbose=1,save_best_only=True)\n",
    "early_stop = EarlyStopping(monitor=early_stop_monitor, mode='min',\n",
    "                               patience=patience, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44302, saving model to /home/zsteineh/ez_ssl_results/checkpoint_gen_tl_a0f66459_fold2.h5\n",
      "48/48 - 1s - loss: 0.6256 - accuracy: 0.6499 - val_loss: 0.4430 - val_accuracy: 0.8571\n",
      "Epoch 2/64\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.44302 to 0.31438, saving model to /home/zsteineh/ez_ssl_results/checkpoint_gen_tl_a0f66459_fold2.h5\n",
      "48/48 - 0s - loss: 0.4299 - accuracy: 0.8098 - val_loss: 0.3144 - val_accuracy: 0.8677\n",
      "Epoch 3/64\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.31438 to 0.28177, saving model to /home/zsteineh/ez_ssl_results/checkpoint_gen_tl_a0f66459_fold2.h5\n",
      "48/48 - 0s - loss: 0.3655 - accuracy: 0.8534 - val_loss: 0.2818 - val_accuracy: 0.9101\n",
      "Epoch 4/64\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.28177 to 0.26647, saving model to /home/zsteineh/ez_ssl_results/checkpoint_gen_tl_a0f66459_fold2.h5\n",
      "48/48 - 0s - loss: 0.3188 - accuracy: 0.8758 - val_loss: 0.2665 - val_accuracy: 0.9101\n",
      "Epoch 5/64\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.26647 to 0.25087, saving model to /home/zsteineh/ez_ssl_results/checkpoint_gen_tl_a0f66459_fold2.h5\n",
      "48/48 - 0s - loss: 0.2907 - accuracy: 0.8943 - val_loss: 0.2509 - val_accuracy: 0.9153\n",
      "Epoch 6/64\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.25087 to 0.24806, saving model to /home/zsteineh/ez_ssl_results/checkpoint_gen_tl_a0f66459_fold2.h5\n",
      "48/48 - 0s - loss: 0.2749 - accuracy: 0.8956 - val_loss: 0.2481 - val_accuracy: 0.9259\n",
      "Epoch 7/64\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.24806 to 0.24024, saving model to /home/zsteineh/ez_ssl_results/checkpoint_gen_tl_a0f66459_fold2.h5\n",
      "48/48 - 0s - loss: 0.2748 - accuracy: 0.8983 - val_loss: 0.2402 - val_accuracy: 0.9153\n",
      "Epoch 8/64\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.24024 to 0.23342, saving model to /home/zsteineh/ez_ssl_results/checkpoint_gen_tl_a0f66459_fold2.h5\n",
      "48/48 - 0s - loss: 0.2347 - accuracy: 0.9168 - val_loss: 0.2334 - val_accuracy: 0.9259\n",
      "Epoch 9/64\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.23342\n",
      "48/48 - 0s - loss: 0.2451 - accuracy: 0.9155 - val_loss: 0.2349 - val_accuracy: 0.9259\n",
      "Epoch 10/64\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.23342\n",
      "48/48 - 0s - loss: 0.2309 - accuracy: 0.9207 - val_loss: 0.2368 - val_accuracy: 0.9153\n",
      "Epoch 11/64\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.23342 to 0.22556, saving model to /home/zsteineh/ez_ssl_results/checkpoint_gen_tl_a0f66459_fold2.h5\n",
      "48/48 - 0s - loss: 0.2230 - accuracy: 0.9155 - val_loss: 0.2256 - val_accuracy: 0.9312\n",
      "Epoch 12/64\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.22556 to 0.22461, saving model to /home/zsteineh/ez_ssl_results/checkpoint_gen_tl_a0f66459_fold2.h5\n",
      "48/48 - 0s - loss: 0.2195 - accuracy: 0.9247 - val_loss: 0.2246 - val_accuracy: 0.9259\n",
      "Epoch 13/64\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.22461 to 0.21773, saving model to /home/zsteineh/ez_ssl_results/checkpoint_gen_tl_a0f66459_fold2.h5\n",
      "48/48 - 0s - loss: 0.2090 - accuracy: 0.9181 - val_loss: 0.2177 - val_accuracy: 0.9206\n",
      "Epoch 14/64\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.21773\n",
      "48/48 - 0s - loss: 0.2112 - accuracy: 0.9247 - val_loss: 0.2262 - val_accuracy: 0.9206\n",
      "Epoch 15/64\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.21773\n",
      "48/48 - 0s - loss: 0.2102 - accuracy: 0.9155 - val_loss: 0.2244 - val_accuracy: 0.9153\n",
      "Epoch 16/64\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.21773\n",
      "48/48 - 0s - loss: 0.1975 - accuracy: 0.9313 - val_loss: 0.2207 - val_accuracy: 0.9206\n",
      "Epoch 17/64\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.21773 to 0.21681, saving model to /home/zsteineh/ez_ssl_results/checkpoint_gen_tl_a0f66459_fold2.h5\n",
      "48/48 - 0s - loss: 0.1920 - accuracy: 0.9300 - val_loss: 0.2168 - val_accuracy: 0.9259\n",
      "Epoch 18/64\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.21681\n",
      "48/48 - 0s - loss: 0.1818 - accuracy: 0.9458 - val_loss: 0.2206 - val_accuracy: 0.9206\n",
      "Epoch 19/64\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.21681 to 0.20638, saving model to /home/zsteineh/ez_ssl_results/checkpoint_gen_tl_a0f66459_fold2.h5\n",
      "48/48 - 0s - loss: 0.1972 - accuracy: 0.9300 - val_loss: 0.2064 - val_accuracy: 0.9312\n",
      "Epoch 20/64\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.20638\n",
      "48/48 - 0s - loss: 0.1734 - accuracy: 0.9511 - val_loss: 0.2101 - val_accuracy: 0.9259\n",
      "Epoch 21/64\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.20638\n",
      "48/48 - 0s - loss: 0.1821 - accuracy: 0.9379 - val_loss: 0.2204 - val_accuracy: 0.9312\n",
      "Epoch 22/64\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.20638\n",
      "48/48 - 0s - loss: 0.1757 - accuracy: 0.9432 - val_loss: 0.2089 - val_accuracy: 0.9206\n",
      "Epoch 23/64\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.20638\n",
      "48/48 - 0s - loss: 0.1735 - accuracy: 0.9406 - val_loss: 0.2072 - val_accuracy: 0.9206\n",
      "Epoch 24/64\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.20638\n",
      "48/48 - 0s - loss: 0.1863 - accuracy: 0.9392 - val_loss: 0.2102 - val_accuracy: 0.9206\n",
      "Epoch 25/64\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.20638\n",
      "48/48 - 0s - loss: 0.1714 - accuracy: 0.9432 - val_loss: 0.2090 - val_accuracy: 0.9153\n",
      "Epoch 26/64\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.20638\n",
      "48/48 - 0s - loss: 0.1783 - accuracy: 0.9445 - val_loss: 0.2174 - val_accuracy: 0.9206\n",
      "Epoch 27/64\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.20638\n",
      "48/48 - 0s - loss: 0.1704 - accuracy: 0.9458 - val_loss: 0.2242 - val_accuracy: 0.9101\n",
      "Epoch 28/64\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.20638\n",
      "48/48 - 0s - loss: 0.1623 - accuracy: 0.9485 - val_loss: 0.2122 - val_accuracy: 0.9259\n",
      "Epoch 29/64\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.20638\n",
      "48/48 - 0s - loss: 0.1632 - accuracy: 0.9538 - val_loss: 0.2190 - val_accuracy: 0.9206\n",
      "Epoch 30/64\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.20638\n",
      "48/48 - 0s - loss: 0.1584 - accuracy: 0.9445 - val_loss: 0.2170 - val_accuracy: 0.9259\n",
      "Epoch 31/64\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.20638\n",
      "48/48 - 0s - loss: 0.1586 - accuracy: 0.9498 - val_loss: 0.2110 - val_accuracy: 0.9206\n",
      "Epoch 32/64\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.20638\n",
      "48/48 - 0s - loss: 0.1576 - accuracy: 0.9538 - val_loss: 0.2136 - val_accuracy: 0.9048\n",
      "Epoch 33/64\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.20638\n",
      "48/48 - 0s - loss: 0.1508 - accuracy: 0.9511 - val_loss: 0.2238 - val_accuracy: 0.9101\n",
      "Epoch 34/64\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.20638\n",
      "48/48 - 0s - loss: 0.1543 - accuracy: 0.9511 - val_loss: 0.2113 - val_accuracy: 0.9153\n"
     ]
    }
   ],
   "source": [
    "h = transfer_model.fit(x_train, y_train, batch_size = 16, epochs = epochs, \n",
    "                        verbose = 2, validation_data=(x_val, y_val),\n",
    "                        callbacks=[checkpointer,early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95772787 0.93121693 0.86827957]\n"
     ]
    }
   ],
   "source": [
    "transfer_model.load_weights(chckpt_path)\n",
    "acc_lst = []\n",
    "preds = transfer_model.predict(x_train).argmax(axis = -1) \n",
    "acc_lst.append(np.mean(preds == y_train.argmax(axis=-1)))\n",
    "preds = transfer_model.predict(x_val).argmax(axis=-1)\n",
    "acc_lst.append(np.mean(preds == y_val.argmax(axis=-1)))\n",
    "preds = transfer_model.predict(X_test2).argmax(axis = -1)\n",
    "acc_lst.append(np.mean(preds == y_test2.argmax(axis=-1)))\n",
    "\n",
    "print(np.asarray(acc_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ez_ss_dl_venv",
   "language": "python",
   "name": "ez_ss_dl_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
